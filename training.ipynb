{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>I have been experiencing a skin rash on my arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>My skin has been peeling, especially on my kne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>I have been experiencing joint pain in my fing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>There is a silver like dusting on my skin, esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>My nails have small dents or pits in them, and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      label                                               text\n",
       "0           0  Psoriasis  I have been experiencing a skin rash on my arm...\n",
       "1           1  Psoriasis  My skin has been peeling, especially on my kne...\n",
       "2           2  Psoriasis  I have been experiencing joint pain in my fing...\n",
       "3           3  Psoriasis  There is a silver like dusting on my skin, esp...\n",
       "4           4  Psoriasis  My nails have small dents or pits in them, and..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Symptom2Disease.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of categories of diseases are: 24\n"
     ]
    }
   ],
   "source": [
    "num_categories = df['label'].nunique()\n",
    "print(\"The number of categories of diseases are:\", num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input (text) and output (label) columns\n",
    "text_data = df['text'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 9ms/step - loss: 4.2173 - accuracy: 0.0312\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 3.8045 - accuracy: 0.0542\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 3.5560 - accuracy: 0.0500\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 3.3875 - accuracy: 0.0688\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 3.2822 - accuracy: 0.0625\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 3.1820 - accuracy: 0.0969\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 3.0183 - accuracy: 0.1385\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 2.8011 - accuracy: 0.1740\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 2.5516 - accuracy: 0.2396\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.3874 - accuracy: 0.2542\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.2329 - accuracy: 0.2969\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0401 - accuracy: 0.3667\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.8634 - accuracy: 0.4198\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.7698 - accuracy: 0.4531\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.5902 - accuracy: 0.4917\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.4809 - accuracy: 0.5406\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.3181 - accuracy: 0.5885\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2817 - accuracy: 0.5792\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.2091 - accuracy: 0.6125\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.1211 - accuracy: 0.6562\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.0910 - accuracy: 0.6698\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.0220 - accuracy: 0.6906\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.9347 - accuracy: 0.7406\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8742 - accuracy: 0.7302\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.8728 - accuracy: 0.7521\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.8661 - accuracy: 0.7573\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7916 - accuracy: 0.7833\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.7453 - accuracy: 0.7979\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.7617 - accuracy: 0.7792\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.7075 - accuracy: 0.8073\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5997 - accuracy: 0.8490\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.6900 - accuracy: 0.8156\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6471 - accuracy: 0.8167\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6345 - accuracy: 0.8375\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6101 - accuracy: 0.8333\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5975 - accuracy: 0.8552\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5967 - accuracy: 0.8479\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5869 - accuracy: 0.8427\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5382 - accuracy: 0.8625\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5266 - accuracy: 0.8667\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5427 - accuracy: 0.8635\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5214 - accuracy: 0.8781\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4829 - accuracy: 0.8844\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4630 - accuracy: 0.8844\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4596 - accuracy: 0.8792\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.9094\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3904 - accuracy: 0.9177\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4741 - accuracy: 0.8875\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4421 - accuracy: 0.8948\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4368 - accuracy: 0.9042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2eeec38af70>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "text_train, text_test, labels_train, labels_test = train_test_split(text_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a tokenizer and fit it on the training text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "# Convert the text data to sequences of tokens\n",
    "sequences_train = tokenizer.texts_to_sequences(text_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_sequence_length = max(len(seq) for seq in sequences_train)\n",
    "sequences_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "sequences_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "# Determine the number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Define the deep learning model architecture\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),  # Add L2 regularization\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Add dropout layer\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "model.fit(sequences_train, labels_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.8208\n",
      "Accuracy: 0.8208333253860474\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(sequences_test, labels_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for prediction\n",
    "def predict_disease(text):\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('disease_model.h5')\n",
    "\n",
    "    # Preprocess the input text\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
    "\n",
    "    # Make the prediction\n",
    "    predicted_probs = model.predict(sequence)[0]\n",
    "    predicted_class = tf.argmax(predicted_probs).numpy()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    # Calculate the confidence score\n",
    "    predicted_prob = predicted_probs[predicted_class]\n",
    "\n",
    "    # Return the predicted class and confidence score\n",
    "    return predicted_label, predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "('Psoriasis', 0.9839914)\n"
     ]
    }
   ],
   "source": [
    "# Test the predict_disease function\n",
    "input_text = \"My nails have small dents or pits in them, and they often feel inflammatory and tender to the touch. Even there are minor rashes on my arms.\"\n",
    "predicted_class = predict_disease(input_text)\n",
    "print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
